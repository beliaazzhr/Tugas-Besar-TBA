{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/beliaazzhr/Tugas-Besar-TBA/blob/main/TUBESTBA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tugas Besar TBA\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### - Anyelir Belia Azzahra 1301200048\n",
        "### - Alvin Tolopan Armando Sibuea 1301201580\n",
        "### - Fakhri Maulana Falah 1301202117"
      ],
      "metadata": {
        "id": "vQi-k9ZDOYOZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cBj8sWqBNm-7"
      },
      "outputs": [],
      "source": [
        "import string"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Tugas Besar TBA\\nOleh:\\nAnyelir Belia Azzahra\\t\\t1301200048\\nAlvin Tolopan Armando Sibuea\\t1301201580\\nFakhri Maulana Falah\\t\\t1301202117\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_imofHYQqUH",
        "outputId": "e04206b6-9136-4803-d39d-78de34e81304"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tugas Besar TBA\n",
            "Oleh:\n",
            "Anyelir Belia Azzahra\t\t1301200048\n",
            "Alvin Tolopan Armando Sibuea\t1301201580\n",
            "Fakhri Maulana Falah\t\t1301202117\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lexical Analyzer"
      ],
      "metadata": {
        "id": "mKhJlb4QdSKK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def LexicalAnalysis(kalimat):\n",
        "  print(\"\\n====== Penganalisis Leksikal ====== \\n\")\n",
        "  alphabet_list = list(string.ascii_lowercase)\n",
        "  state_list = [\n",
        "                'q0','q1','q2','q3','q4','q5','q6','q7','q8','q9','q10',\n",
        "                'q11','q12','q13','q14','q15','q16','q17','q18','q19',\n",
        "                'q20','q21','q22','q23','q24','q25','q26', 'q27', 'q28', \n",
        "                'q29', 'q30', 'q31', 'q32'\n",
        "                ]\n",
        "  transition_table = {}\n",
        "\n",
        "  for state in state_list:\n",
        "    for alphabet in alphabet_list:\n",
        "      transition_table[(state, alphabet)] = 'error'\n",
        "    transition_table[(state, '#')] = 'error'\n",
        "    transition_table[(state, ' ')] = 'error'\n",
        "  \n",
        "  # Deskripsi Context Free Grammar untuk Bahasa Jawa\n",
        "  # S = {SB, VB, OB}\n",
        "  # SB = adi | mas | aku\n",
        "  # VB =  mangan | moco | nganggo | nggawa\n",
        "  # OB = sego | buku | klambi \n",
        "\n",
        "\n",
        "  # first state\n",
        "  transition_table[(\"q0\", \" \")] = \"q0\"\n",
        "\n",
        "  # Finish state\n",
        "  transition_table[(\"q3\", \"#\")] = \"accept\"\n",
        "  transition_table[(\"q3\", \" \")] = \"q4\"\n",
        "\n",
        "  transition_table[(\"q4\", \"#\")] = \"accept\"\n",
        "  transition_table[(\"q4\", \" \")] = \"q4\"\n",
        "\n",
        "  # Untuk String mas\n",
        "  transition_table[(\"q0\", \"m\")] = \"q6\"\n",
        "  transition_table[(\"q6\", \"a\")] = \"q7\"\n",
        "  transition_table[(\"q7\", \"s\")] = \"q3\"\n",
        "  transition_table[(\"q4\", \"m\")] = \"q6\"\n",
        "\n",
        "  # Untuk String nganggo\n",
        "  transition_table[(\"q0\", \"n\")] = \"q16\"\n",
        "  transition_table[(\"q16\", \"g\")] = \"q17\"\n",
        "  transition_table[(\"q17\", \"a\")] = \"q18\"\n",
        "  transition_table[(\"q18\", \"n\")] = \"q19\"\n",
        "  transition_table[(\"q19\", \"g\")] = \"q20\"\n",
        "  transition_table[(\"q20\", \"g\")] = \"q21\"\n",
        "  transition_table[(\"q21\", \"o\")] = \"q3\"\n",
        "  transition_table[(\"q4\", \"n\")] = \"q16\"\n",
        "\n",
        "  # Untuk String nggawa\n",
        "  transition_table[(\"q0\", \"n\")] = \"q16\"\n",
        "  transition_table[(\"q16\", \"g\")] = \"q17\"\n",
        "  transition_table[(\"q17\", \"g\")] = \"q22\"\n",
        "  transition_table[(\"q22\", \"a\")] = \"q23\"\n",
        "  transition_table[(\"q23\", \"w\")] = \"q24\"\n",
        "  transition_table[(\"q24\", \"a\")] = \"q3\"\n",
        "  transition_table[(\"q4\", \"n\")] = \"q16\"\n",
        "\n",
        "  # Untuk String mangan\n",
        "  transition_table[(\"q0\", \"m\")] = \"q6\"\n",
        "  transition_table[(\"q6\", \"a\")] = \"q7\"\n",
        "  transition_table[(\"q7\", \"n\")] = \"q22\"\n",
        "  transition_table[(\"q22\", \"g\")] = \"q23\"\n",
        "  transition_table[(\"q23\", \"a\")] = \"q24\"\n",
        "  transition_table[(\"q24\", \"n\")] = \"q3\"\n",
        "  transition_table[(\"q4\", \"m\")] = \"q16\"\n",
        "\n",
        "  # Untuk String 'adi'\n",
        "  transition_table[(\"q0\", \"a\")] = \"q1\"\n",
        "  transition_table[(\"q1\", \"d\")] = \"q2\"\n",
        "  transition_table[(\"q2\", \"i\")] = \"q3\"\n",
        "  transition_table[(\"q4\", \"a\")] = \"q1\"\n",
        "\n",
        "  # Untuk String 'aku' \n",
        "  transition_table[(\"q0\", \"a\")] = \"q1\"\n",
        "  transition_table[(\"q1\", \"k\")] = \"q5\"\n",
        "  transition_table[(\"q5\", \"u\")] = \"q3\"\n",
        "  transition_table[(\"q4\", \"a\")] = \"q1\"\n",
        "  \n",
        "  # Untuk String 'moco'\n",
        "  transition_table[(\"q0\", \"m\")] = \"q6\"\n",
        "  transition_table[(\"q6\", \"o\")] = \"q11\"\n",
        "  transition_table[(\"q11\", \"c\")] = \"q12\"\n",
        "  transition_table[(\"q12\", \"o\")] = \"q3\"\n",
        "  transition_table[(\"q4\", \"m\")] = \"q6\"\n",
        "\n",
        "  # string \"sego\"\n",
        "  transition_table[(\"q0\", \"s\")] = \"q13\"\n",
        "  transition_table[(\"q13\", \"e\")] = \"q14\"\n",
        "  transition_table[(\"q14\", \"g\")] = \"q15\"\n",
        "  transition_table[(\"q15\", \"o\")] = \"q3\"\n",
        "  transition_table[(\"q4\", \"s\")] = \"q13\"\n",
        "\n",
        "  # string \"buku\"\n",
        "  transition_table[(\"q0\", \"b\")] = \"q25\"\n",
        "  transition_table[(\"q25\", \"u\")] = \"q26\"\n",
        "  transition_table[(\"q26\", \"k\")] = \"q27\"\n",
        "  transition_table[(\"q27\", \"u\")] = \"q3\"\n",
        "  transition_table[(\"q4\", \"b\")] = \"q25\"\n",
        "\n",
        "  # string \"klambi\"\n",
        "  transition_table[(\"q0\", \"k\")] = \"q28\"\n",
        "  transition_table[(\"q28\", \"l\")] = \"q29\"\n",
        "  transition_table[(\"q29\", \"a\")] = \"q30\"\n",
        "  transition_table[(\"q30\", \"m\")] = \"q31\"\n",
        "  transition_table[(\"q31\", \"b\")] = \"q32\"\n",
        "  transition_table[(\"q32\", \"i\")] = \"q3\"\n",
        "  transition_table[(\"q4\", \"k\")] = \"q28\"\n",
        "\n",
        "  #analisis\n",
        "  idx_char = 0\n",
        "  state = 'q0'\n",
        "  current_token = ''\n",
        "  while state!='accept':\n",
        "    current_char = input_string[idx_char]\n",
        "    current_token += current_char\n",
        "    state = transition_table[(state, current_char)]\n",
        "    if state=='q3':\n",
        "      print('token saiki: ' , current_token,', bener')\n",
        "      current_token = ''\n",
        "    if state== 'error':\n",
        "      print('error')\n",
        "      break;\n",
        "    idx_char = idx_char + 1\n",
        "  \n",
        "  # akhir analisis\n",
        "  if state=='accept':\n",
        "    print('kabeh token di input: ', sentence, ', bener') \n",
        "    \n",
        "  return LexicalAnalysis\n"
      ],
      "metadata": {
        "id": "GuEdfsLIRIRh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parser"
      ],
      "metadata": {
        "id": "LzOcx_TVdQp1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Parser(sentence):\n",
        "    print(\"\\n====== Parser ====== \\n\")\n",
        "    tokens = sentence.lower().split()\n",
        "    tokens.append('EOS')\n",
        "    # symbols definition\n",
        "    non_terminals = ['S','SB','VB','OB']\n",
        "    terminals = ['adi','mas','aku','mangan','moco', 'nganggo','nggawa','sego','buku','klambi' ]\n",
        "\n",
        "    parse_table = {}\n",
        "\n",
        "    parse_table[('S','adi')] = ['SB','VB','OB']\n",
        "    parse_table[('S','mas')] = ['SB','VB','OB']\n",
        "    parse_table[('S','aku')] = ['SB','VB','OB']\n",
        "    parse_table[('S','mangan')] = ['error']\n",
        "    parse_table[('S','moco')] = ['error']\n",
        "    parse_table[('S','nganggo')] = ['error']\n",
        "    parse_table[('S','nggawa')] = ['error']\n",
        "    parse_table[('S','sego')] = ['error']\n",
        "    parse_table[('S','buku')] = ['error']\n",
        "    parse_table[('S','klambi')] = ['error']\n",
        "    parse_table[('S','EOS')] = ['error']\n",
        "\n",
        "    parse_table[('SB','adi')] = ['adi']\n",
        "    parse_table[('SB','mas')] = ['mas']\n",
        "    parse_table[('SB','aku')] = ['aku']\n",
        "    parse_table[('SB','mangan')] = ['error']\n",
        "    parse_table[('SB','moco')] = ['error']\n",
        "    parse_table[('SB','nganggo')] = ['error']\n",
        "    parse_table[('SB','nggawa')] = ['error']\n",
        "    parse_table[('SB','sego')] = ['error']\n",
        "    parse_table[('SB','buku')] = ['error']\n",
        "    parse_table[('SB','klambi')] = ['error']\n",
        "    parse_table[('SB','EOS')] = ['error']\n",
        "\n",
        "    parse_table[('VB','adi')] = ['error']\n",
        "    parse_table[('VB','mas')] = ['error']\n",
        "    parse_table[('VB','aku')] = ['error']\n",
        "    parse_table[('VB','mangan')] = ['mangan']\n",
        "    parse_table[('VB','moco')] = ['moco']\n",
        "    parse_table[('VB','nganggo')] = ['nganggo']\n",
        "    parse_table[('VB','nggawa')] = ['nggawa']\n",
        "    parse_table[('VB','sego')] = ['error']\n",
        "    parse_table[('VB','buku')] = ['error']\n",
        "    parse_table[('VB','klambi')] = ['error']\n",
        "    parse_table[('VB','EOS')] = ['error']\n",
        "\n",
        "    parse_table[('OB','adi')] = ['error']\n",
        "    parse_table[('OB','mas')] = ['error']\n",
        "    parse_table[('OB','aku')] = ['error']\n",
        "    parse_table[('OB','mangan')] = ['error']\n",
        "    parse_table[('OB','moco')] = ['error']\n",
        "    parse_table[('OB','nganggo')] = ['error']\n",
        "    parse_table[('OB','nggawa')] = ['error']\n",
        "    parse_table[('OB','sego')] = ['sego']\n",
        "    parse_table[('OB','buku')] = ['buku']\n",
        "    parse_table[('OB','klambi')] = ['klambi']\n",
        "    parse_table[('OB','EOS')] = ['error']\n",
        "\n",
        "    #stack initialization\n",
        "    stack = []\n",
        "    stack.append('#')\n",
        "    stack.append('S')\n",
        "\n",
        "    #input reading initialization\n",
        "    idx_token = 0\n",
        "    symbol = tokens[idx_token]\n",
        "\n",
        "    #parse table process\n",
        "    while (len(stack) > 0):\n",
        "        top = stack[len(stack)-1]\n",
        "        print('top = ', top)\n",
        "        print('symbol = ', symbol)\n",
        "        if top in terminals:\n",
        "            print('top adalah simbol terminal')\n",
        "            if top == symbol:\n",
        "                stack.pop()\n",
        "                idx_token = idx_token + 1\n",
        "                symbol = tokens[idx_token]\n",
        "                if symbol == \"EOS\":\n",
        "                    stack.pop()\n",
        "                    print('isi stack:', stack)\n",
        "            else:\n",
        "                print('error')\n",
        "                break;\n",
        "        elif top in non_terminals:\n",
        "            print('top adalah simbol non-terminal')\n",
        "            if parse_table[(top, symbol)][0] != 'error':\n",
        "                stack.pop()\n",
        "                symbol_to_be_pushed = parse_table[(top, symbol)]\n",
        "                for i in range(len(symbol_to_be_pushed)-1,-1,-1):\n",
        "                    stack.append(symbol_to_be_pushed[i])\n",
        "            else:\n",
        "                print('error')\n",
        "                break;\n",
        "        else:\n",
        "            print('error')\n",
        "            break;\n",
        "        print('isi stack: ', stack)\n",
        "        print()\n",
        "\n",
        "    #conlusion\n",
        "    print()\n",
        "    if symbol == 'EOS' and len(stack)== 0:\n",
        "        print('Input string ','\"', sentence,'\"', ' diterima, sesuai Grammar')\n",
        "    else:\n",
        "        print('Error, input string:','\"', sentence,'\"', ', tidak diterima, tidak sesuai Grammar')\n",
        "\n",
        "    return Parser"
      ],
      "metadata": {
        "id": "x0JCCdl_dZPi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Output"
      ],
      "metadata": {
        "id": "Pf93Rn7yfM_l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Terminal: adi - mas - aku | mangan - moco - nganggo - nggawa | sego - buku - klambi \\n\")\n",
        "sentence = input(\"Ketik teks ning kene:  \") \n",
        "input_string = sentence.lower()+'#'\n",
        "LexicalAnalysis(sentence)\n",
        "Parser(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6BNBfdffPDB",
        "outputId": "9da43970-6c86-43e0-cee4-97ce417d3910"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Terminal: adi - mas - aku | mangan - moco - nganggo - nggawa | sego - buku - klambi \n",
            "\n",
            "Ketik teks ning kene:  klambi moco mas\n",
            "\n",
            "====== Penganalisis Leksikal ====== \n",
            "\n",
            "token saiki:  klambi , bener\n",
            "token saiki:   moco , bener\n",
            "token saiki:   mas , bener\n",
            "kabeh token di input:  klambi moco mas , bener\n",
            "\n",
            "====== Parser ====== \n",
            "\n",
            "top =  S\n",
            "symbol =  klambi\n",
            "top adalah simbol non-terminal\n",
            "error\n",
            "\n",
            "Error, input string: \" klambi moco mas \" , tidak diterima, tidak sesuai Grammar\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function __main__.Parser>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    }
  ]
}